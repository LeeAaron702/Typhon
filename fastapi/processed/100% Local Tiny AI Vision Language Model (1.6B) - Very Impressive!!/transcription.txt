 Who is this Taylor Swift? Where in the world is this?  This is New York City, specifically in the financial district. What kind of field is this man an expert in?  This man is an expert in the field of computer vision and machine learning. What two destinations does this arrow point to?  Who is winning this fight?  What animal is inside the red square? This was just a few other things we are gonna test out today, so let's get started.  This video was sponsored by Brilliant. Okay, so this is just a very simplified shot of how this works.  We are using the Moon Dream Titan, a vision 1.6 billion parameters model here.  So we can choose between kind of speech input to a faster whisper. We can just do regular text input like prompts.  We can also do video input where you can slice up two frames. I'm gonna show you that.  And we can choose what kind of description format we want.  We can get it back in just plain text or we can get it back in speech.  If you want to know more about how I do the speech-to-speech function,  you can just go back to one of my previous videos and you can learn all about that.  But now let's take a quick look at the tiny vision model before we do some more testing.  This is the Moon Dream GitHub page. Go check it out. I'll leave a link in the description below.  You can see this is a 1.6 billion parameter model. They have some benchmarks here. Pretty good results for being so small.  It's very quick. That's what I liked about it. So you can see here, we have some examples you can go through, how we can install it.  So definitely go check them out and learn something and speaking of learning.  Have you ever wondered how the magic of large language model work or maybe you're keen on diving into the world of programming,  but you don't know where to start? Well Brilliant Total, the sponsor of today's video is your place to understand and master these skills.  Brilliant makes learning engaging accessible, especially in fields like computer science, math and data science.  What sets Brilliant apart is their interactive approach where you're not just passively consuming information.  You're actively engaging and solving real-world problems.  Like the course How LLM's work, which takes you on an exciting journey to unravel the mysteries of LLM's,  you get a chance to kind of peek under the hood and really grasp how they function.  And for those who are itching to get their hands dirty with coding, the thinking in code course is a perfect start.  It's designed to build a robust foundation in computational problems solving,  starting with the basics and moving on to more complex challenges.  With Brilliant learning in Sabrese, you get interactive lessons, helpful hints and the lessons stick with you long after you're done.  To start your journey head over to Brilliant.org slash all about AI or just pick the link in the description for a free 30-day trial and the first 200 of you will get 20% of the annual plan.  A big thanks to Brilliant for sponsoring this video.  Okay, so the first test I thought we could do was just play in text, so we have a Mistral 7B model here that is running on LLM Studio on this local server.  So we can interact with Mistral 7B2 and we have our process image function that is actually using the Moon Dream 1 model.  So we are loading images. We also have some functionality that can kind of pop the image up so we can see the image we are talking about.  We have an image path and here is kind of our input.  So ask a question about the image or type exit to quit.  This is just a true loop until we break it.  And here is kind of the Mistral 7B part and you can see we join all the answers in kind of into a list.  So Mistral B can get the full reference when we feed kind of all the answers here into the prompt for Mistral 7B.  You will see this now when we test it. So yeah, let's just do that.  Okay, so let's run this in kind of real time so you can see how fast this is.  So here we are kind of loading the Wishing model I think.  We should get the image pop-up soon.  Yeah, that's good. So this is Taylor Swift.  Who is this? This is our input prompt, right?  And you can see pretty fast.  And here we get kind of a summary so far of the image descriptions we can follow up with what is she wearing?  This is our input prompt again.  So we get kind of an appended description here.  So she's wearing a green dress and you can see this is implemented into our summary.  So we can follow up what color is her eyes.  Her eyes are blue. Yeah, working quite good.  Does she have earrings?  Okay, so I put just earrings. So yes, she has earring in her left ear.  So here we can kind of see the summary.  So I got this image description for you. It's Taylor Swift.  This is seeing everyone on this picture.  It's wearing a stunning green dress.  Brings out her eyes, her eyes are blue.  Yeah, so I think we kind of are creating like a big, great summary of the image here now as we append this.  So pretty cool.  I think we're just going to call it now for the text version and move on to kind of,  let's take a look at the video part.  Okay, so for the video version, we need to use FFmpeg. We need to use movie pie.  I got a video on that. If you just want to go back to some of my previous one and check that out.  We have the Mr. B77B function still because we want to, yeah, do some more work on the results.  We have the same process image function as before.  Moon dream one.  We want to convert MP3 MP4 to MP3 because some videos  we want to take the audio to and process that. I'm going to show you.  But for the first video, we are just going to extract the frames.  We're going to do a frame interval of one frame per second.  So if the video is in 60 frames, then we get one per second right.  And we, yeah, we set our video part and stuff.  And yeah, it should be pretty straightforward.  And here you can kind of see the explanation that we are going to get from Mr. L7B.  So we just feed in the video description from all the frames.  So basically what we do is we send every frame through the vision model.  We collect all the descriptions and put them into one big description.  And then we use Mr. L7B to kind our, from the video description above, write a full list of names.  Because the video we are going to take a look at is just a bunch of celebrities.  And we're going to try to identify them all.  So let me show you the video then.  So this is the video.  You can see it should be pretty easy because if we start over here,  you can see we have Celia Murphy here, Meryl Streep.  And we got some other celebrities.  I don't know all about all these celebrities.  So this is Margot Robbie.  So the model has the names, right?  Julia Garner, Taylor Swift.  Yeah, we can just, yeah.  So there's a bunch of celebrities.  So if we go to our image folder here now, let's pop that up here.  So when we are running this now, you can see all the frames is going to be put into this.  So let's exit this.  Yeah, fire up the video version.  Okay, so I'm running this now.  So kind of the first thing is going to happen is we're going to get some frames here.  So you can kind of see all the frames popping up into our folder here.  And we're going to have point the division model to this folder here.  And then it's going to go through every single frame here.  You can see we captured 38 frames.  And this is, of course, going to take a bit more time because we need to go to 38 images.  So we're just going to let this run and let's take a look at the final result.  Wow, that was pretty quick.  I wasn't expecting that a bit so quick.  So yeah, okay.  So let's take a look at the result there.  I thought we had to go out.  So we have Meryl Streep, Leo DiCaprio, Kate Capshaw, Steven Spielberg, Gloria Campano.  I don't think I saw her.  Casa Nova, Margot Robbie, Jula Garner, Taylor Swift.  So yeah, pretty good job, I think.  I think he captured everything, but it made some up.  Gloria Campano.  I guess we saw her.  Give me a second here.  Yeah, but it didn't catch Bradley Cooper.  That was my bad.  Maybe that's Casa Nova.  I don't know.  Okay, so I think we have to give this a pass.  Now let's try a video with kind of some audio.  So now we have kind of added in audio.  So now we kind of activated our faster whisper.  So we're going to pick the medium model.  We're running on cuter cores.  We changed up our prompt of it.  We kind of added in audio description.  Now we're going to, from the video and audio description above, right?  A detailed summary.  Okay.  So this is the video we're going to pass through.  These five tanks are literally about to rain missiles upon this $500,000.  And any money that doesn't get destroyed, I'm giving to Blake.  Okay, so it's just a Mr. Beast clip.  Let's just run it.  Okay.  So let's run this.  So the first thing is going to be the transcription.  Yeah, you can see we're using move by turning into MP3 file.  Here we are using faster whisper.  That was quite quick.  So here is, yeah, looks pretty good.  So this is our transcription.  And we saw all the frames pop up here.  I put this down to 120 now.  So we got like every other second.  And yeah, now let's just wait for the description.  Okay.  So let's check it out.  Let's do it a bit so we can take a read a bit here.  So in this video, there are five tanks positioning fire missiles at $500,000 worth of money.  Yeah, that's good.  The speaker plans to give the money not destroyed to Blake.  Yeah.  Nice.  The recipients given 24 hours before the tanks to fire upon their money.  Very good.  What can I say?  That is exactly what the clip is about.  So yeah, very impressed to be honest with this small vision model here.  Of course, I don't think it would have been so good if we didn't add the sound clip.  But yeah, that's just another feature.  Okay.  So the final test we are going to do is actually using speech to speech.  So I can talk into my mic.  I can get a response back from the open voice model.  Also for this, I have a video.  So you can just go back in my library if you want to know how to set this up.  It's completely open source.  It's fully local.  So you can be offline when you do this.  This is of course the same with what we are doing now.  So we're just going to skip the Python code here.  And we're just going to go straight into the testing.  And the first image is this one.  So you can see this.  So I put a couple of arrows here.  So I'm going to ask what kind of parts are these arrow pointing to and see if we can identify that.  So yeah, let's just run it.  Okay.  So let's run this now should be pretty much the same.  We should get the image popping up here anytime.  And let's ask about the arrows.  What destinations is the arrow pointing to?  The arrow is pointing to Central Park and Kennedy Airport.  Yeah, that's good.  So that was the only thing I wanted to know.  We can of course continue asking more questions about the image.  But I just want to move on to the next part.  So yeah, good start.  Let's ask a bit about this image.  I wanted to ask about the mood of the dog and who is likely to win the fight.  Let's try this.  What is the mood of the dog in the image?  The dog in the image appears to be angry or aggressive as it is scrolling and showing its  teeth while facing the cat.  Who is most likely to win this fight?  The dog is most likely to win this fight as it is a larger and stronger animal.  Dogs typically have a higher bite force and are more agile, which gives them an advantage  in physical confrontations, cats on the other hand, or smaller and have a more agile body  structure.  But their bite force is not as strong as dogs.  In this image, the dog is showing a more aggressive and dominant behavior while the cat is trying.  Okay, so that was a pretty good response.  But I kind of think the cat would win.  But yeah, who am I to say?  So yeah, good response there, I think.  Okay, so next up we have this image.  So you can kind of see I went into paint.  I took this red square and put it around the swing here.  So let's see if we can identify this.  So yeah, let's just run this now.  Okay.  So we should have pretty much the basic setup.  The image is going to pop up and we can ask a question.  Describe all the objects inside the red square in the image.  The red square in the image represents a portion of the lawn, likely a playground or a play  area for children.  There is a swing set in the area.  With two swings visible.  Additionally, there are two cars parked in the vicinity, possibly belonging to the residents of the  houses nearby.  The houses are situated on the hillside, overlooking the playground.  Yeah, that was pretty good.  Imagine a swing, imagine a yard, imagine like the playground, imagine the cars here too.  That was a bit off-scope, but yeah, I accept that.  Very good.  Okay, so the last test is going to be text.  I found something on the verge here.  So this is about Google's new video generation AI.  So we're going to ask if we can summarize this text.  My expectations are quite low here, but hey, let's give it a shot.  Can you summarize the most important parts of the text in the image?  The image shows a summary of a YouTube video, which is about a new video generation AI  model called Luminaire.  The video explains how Luminaire uses a new fusion process to create a base frame from a  given prompt.  The AI model then uses this base frame to generate a series of frames, which are then combined  to create a seamless motion video.  The video also includes a comparison of the number of frames generated by Luminaire to those  generated by another AI model called space time you in.  In one sentence, can you describe Luminaire?  An AI that uses a new diffusion model called space time konnet or stuffnet that figures  out where things are in video and creates a base frame from the prompt.  Okay, so the final answer was pretty good.  The rest was a bit.  So I'm not 100% sure about text.  It's clearly understanding something, but I have to test it more to see if, yeah, to  find out kind of how good it is actually.  So yeah, that was basically what I wanted to go through today.  If you are interested in testing this out for yourself, just click on my link in the description  below and become a member of the channel.  I will invite you to the Community GitHub.  You will get access to the Community Discord and, of course, all my previous scripts and  stuff I have been doing.  So don't forget to check out Moon dream.  Don't forget to check out Brilliant.org.  And yeah, have a great day and I'll see you on Wednesday.